## Билет 1: Параллелизм в пределах одного процессорного ядра и контекста выполнения: архитектурные возможности и компиляторные подходы к повышению параллелизма на уровне команд.

### 1. Конвейер
Для того чтобы ускорить исполнение машинных инструкций был придуман конвейер. В 
общем случае инструкции проходят 5 этапов:

1) __Fetch__ - Чтение байтов инструкции из памяти
2) __Decode__ - Парсинг команды, помещение регистров в _регистровый файл_
3) __Execute__ - Исполнение команды (вычисление результата 
исполнение на одном из доступных ALU (Арифметико-логическое устройство)
4) __Memory access__ - Чтение или запись в оперативную память
5) __Writeback__ - Запись результата в _регистровый файл_

Вместо того, чтобы исполнять все шаги последовательно для каждой инструкции, 
можно организовать конвейер - как только инструкция пройдет первый этап, 
посылать на первый этап следующую инструкцию. Таким образом удастся добиться 
некоторого параллелизма исполнения.

```
Single-cycle processor
       IF  ID  EX  WB
                       IF  ID  EX  WB
Pipelined processor
       IF  ID  EX  WB
           IF  ID  EX  WB
               IF  ID  EX  WB
                   IF  ID  EX  WB
                       IF  ID  EX  WB
cycle: 0   1   2   3   4   5   6   7
```
Однако в некоторых ситуациях конвейеризация не работает. В качестве примера 
можно рассмотреть ситуацию, когда после вычисления результата какой-либо 
инструкции (например NEG) необходимо записать результат в оперативную память 
(ST). Мы не можем сразу после этапа исполнения для NEG начать исполнять ST, так 
как результат операции NEG еще не записан. Таким образом, возникает т.н. 
"пузырь", то есть весь конвейер ждет, пока результат операции NEG не будет 
записан. Существуют несколько видов зависимостей, из-за которых в конвейере 
возникают "пузыри".

* __Антизависимость__ - запись после чтения
* __Зависимость по выходу__ - запись после записи
* __Истинная__ - чтение после записи
* __Условное ветвление__ (мы не можем предсказать в какую сторону пойдет 
исполнение до вычисления условия
* __Вызов/возврат__ (аналогично предыдущему, мы не можем предугадать куда 
произойдет прыжок)

Для решения проблем с такими зависимостями существует несколько механизмов, о 
которых речь пойдет далее.

### 2. Переименование регистров
Данный подход позволяет решить проблему антизависимостей и зависимостей по 
выходу. С помощью переименования регистров мы можем разнести данные в разные 
регистры, что позволит им быть независимыми. Тогда мы сможем оптимизировать 
конвейер, чтобы в нем не возникало "пузырей". Переименование регистров может 
быть сделано как компилятором, так и поддерживаться аппаратным способом. 
Приведем пример кода на ASM, в котором используется переименования регистров 
для избежания зависимостей.

```nasm
L1: LD r1, [r0]            L1: LD r1, [r0]
    -- bubble --               MOV r3, r0 <- перенесли в другой регистр
    NEG r1                     NEG r1
    -- bubble --               ADD r0, 4
    ST [r0], r1                ST [r3], r1
    ADD r0, 4                  CMP r0, r2
    -- bubble --               JLE L1
    CMP r0, r2
    JLE L1
```

Видно, что удалось избежать зависимостей, что позволило полностью заполнять 
конвейер и завершить итерацию цикла раньше, чем в первом варианте.

Кроме того, можно изменить порядок инструкций, чтобы избежать задержек на 
конвейере. Это называется **Insruction scheduling**. Стоит отметить, что 
изменение порядка инструкций может помочь также сэкономить энергозатраты, 
минимизируя переключение битов.

К минусам данного подхода можно отнести 

* Конфиликт с аллокацией регистров при компиляции (приходится заново 
планировать аллокацию регистров после оптимизации)
* _Зависимости времени компиляции_
* Простейшие алгоритмы _ренейминга_ работают только на ацикличных ГПУ

### 3. Суперскалярное исполнение

Суперскалярным исполнением называют подход, при котором в процессоре имеются 
дублирующие юниты, которые позволяют выполнять __две и более__ инструкции за 
один такт (_независимо от конвейера_). Это позволяет не только ускорить 
исполнение программы, но и оптимизировать некоторые инструкции (например, 
использующие ALU и FPU).

### 4. Спекулятивное исполнение
Спекулятивное исполнение (Speculative Execution) — это техника, при которой 
процессор продолжает выполнение инструкций в некоторой последовательности, даже 
если неизвестно, должны ли они быть выполнены. Это предназначено для повышения 
параллелизма и улучшения общей производительности процессора. 
- Принцип работы:
    - Процессор делает предположение о том, какие инструкции следует выполнить, 
    и начинает их выполнение до того, как окончательно определится, должны ли 
    они быть выполнены.
    - Если предположение было неверным (например, условие ветвления оказалось 
    ложным), процессор отменяет результаты спекулятивного выполнения, возвращая 
    состояние процессора к моменту перед началом спекулятивного блока.

### 5. Branch Prediction

Помимо классических методов избежания зависимостей, может использоваться 
предсказание условных ветвлений и вызовов/возвратов. Данный метод основан на 
возможности с высокой вероятностью предугадать поведение определенных ветвлений. 
Например, JMP в конце цикла, повторяющегося несколько раз, с большой 
вероятностью будет вести на начало итерации. Таким образом, в большинстве своем, 
конвейер заполняется из предположения, что прыжок будет осуществлен на начало 
цикла. Так как выход из цикла будет осуществляться лишь единожды, ошибка 
заполнения конвейера в этом случае будет незначительно на фоне успешно 
предсказанных прыжков на начало итерации. 

Предсказание условных переходов производится несколькими путями:

* __Во время исполнения__. В данном случае предсказание на текущий переход 
строится исходя из поведения данного перехода в предыдущие разы. Так для цикла 
после нескольких итераций процессор будет успешно предсказывать, что исполнение 
будет прыгать на начало итерации, а ошибка предсказания на последней итерации 
будет незначительна на фоне предшествующих успешных предсказаний.
* __При компиляции__. В этом случае мы можем после компиляции программы 
запустить ее вместе с анализатором, который соберет статистику по условным п
ереходам. Далее программу можно будет перекомпилировать с учетом этой 
статистики, чтобы улучшить качество предсказания условных переходов.

Помимо предсказания условных переходов можно предсказывать и адрес вызова и 
возврата из функции, чтобы сразу запускать в конвейер инструкции, которые 
необходимо будет исполнить после исполнения вызова или возврата.

### 6. VLIW
VLIW (Very Long Instruction Word) — это архитектура процессора, которая 
предоставляет компилятору возможность указывать множество инструкций, которые 
могут быть выполнены одновременно, без необходимости динамического 
переупорядочивания инструкций во время выполнения. Это отличает VLIW от 
архитектур с динамическим выделением и переупорядочиванием инструкций, таких 
как Superscalar или Out-of-Order Execution.

Основные характеристики VLIW:

1. **Статическое выделение и исполнение инструкций:**
  Инструкции группируются в длинные слова (very long words), и компилятор 
  статически определяет, какие инструкции можно выполнить параллельно.

2. **Множество функциональных блоков (FU):**
  VLIW-процессоры обычно имеют несколько функциональных блоков, каждый из 
  которых способен выполнить определенные типы инструкций (например, 
  арифметические, логические и загрузка/выгрузка данных).

3. **Отсутствие зависимостей данных между инструкциями:**
  Поскольку инструкции выбираются компилятором исходя из статического анализа 
  кода, предполагается, что нет зависимостей данных между инструкциями в одном 
  слове.

4. **Высокая эффективность использования ресурсов:**
  VLIW-архитектуры обеспечивают высокую степень параллелизма, так как 
  компилятор может эффективно использовать все функциональные блоки процессора 
  без дополнительных накладных расходов на динамическое переупорядочивание.

### 7. Предикаты
Предикаты позволяют развернуть код с ветвлением в линейный код, использующих 
предикативный бит. Это позволяет _одновременно обрабатывать_ несколько веток 
исполнения ценой большего количества инструкций, которые нужно профетчить.


### 8. Out-of-order execution
Процессор может переупорядочивать и выполнять инструкции не в том порядке, в 
котором они поступают, но с учетом зависимостей данных, что позволяет 
эффективно использовать вычислительные ресурсы и избегать простоев.

> Были еще штуки, но они малопонятны и не особо популярны, проигнорим...

## Билет 2: SIMD-расширения: поддержка в ОС и компиляторах, доступные возможности использования (ассемблер, расширения языка, автовекторизация).

### SIMD-инструкции

SIMD-инструкции позволяют производить операции над множеством данных с помощью 
одной инструкции (**S**ingle **I**nstruction **M**ultiple **D**ata). Для 
реализации данного функционала в процессорах были созданы специальные 
инструкции и расширенные регистры (MMX, SSE, AVX в процессорах x86 и VFP, NEON, 
Helium, SVE в Arm-процессорах).

Использование возможностей SIMD:
- Прямое ассемблерное кодирование
- Внутренние функции компилятора (intrinsics)
- Компилятор "generic vectros"
- Автоматическая векторизация
- Языки, специфичные для предметной области ?? (Domain-specific languages) 

Возможности использования SIMD-расширений:
- ASM-код (дрочка с call-convention-ом)
- Intel intrinsics
- Обобщённые векторные операции
- Можно смешивать intrinsic-и и generic vector-ы
- Вызовы memcpy для векторных инструкций

Появление SIMD привело к некоторым трудностям со стороны поддержки операционной 
системы:

* Переключения контекста
* Сигнальные фреймы
* Нелокальный ГПУ

Таким образом для успешной работы данного подхода необходимо, чтобы процессор,
ядро ОС и библиотеки работали сообща.

Из-за этого компилятор не может автоматически векторизовывать данные, поэтому
часто производители процессоров выпускают библиотеки, содержащие т.н. 
интрисики - методы, позволяющие напрямую указывать компилятору на использование 
SIMD-инструкций. Благодаря этому программист может описать несколько вариантов 
обработки данных - для процессоров, поддерживающих SIMD и для процессоров, их 
не поддерживающих. Для этого используется условная компиляция.

## Билет 3: Вычисления с плавающей точкой. Принципы IEEE-754. Ограничения и возможности компиляторной трансляции.

### Хранение чисел с плавающей точкой

Вычисления с плавающей точкой описываются в стандарте IEEE-754. Он описывает 
следующее:

* Формат хранения чисел с плавающей точкой в памяти
* Операции над числами с плавающей точкой и правила их округления
* Исключения

Числа с плавающей точкой хранятся в памяти в виде знака, мантиссы и экспоненты.

$$
    r = (-1)^s \cdot M \cdot 2^E
$$

Однако в данном случае допускается неоднозначность кодировки. Рассмотрим это на 
примере числа `6.`

$$
    6 = (-1)^0 \cdot 0011_b \cdot 2^1 \\
    6 = (-1)^0 \cdot 0110_b \cdot 2^0
$$

Для решения этой проблемы было введено ограничение на мантиссу: 
$M \equiv 1.m_1m_2m_3...$. Таким образом запись числа `6` будет выглядеть 
следующим образом:

$$
    6 = (-1)^0 \cdot 1.100_b \cdot 2^2
$$

При этом остается еще несколько проблем:

* Невозможность представить $0$
* Область низкой точности около нуля

Для решения данных проблем вводятся два типа мантисс. В первую очередь 
выбирается сдвиг экспоненты $E_{bias}$: 

* __матисса нормального диапазона__: 
$M = 1.m_1m_2m_3..., E=E_{bias} + e \text{ if } e > 0$
* __мантисса ненормального диапазона__:
$M = 0.m_1m_2m_3..., E=E_{bias} + 1 \text{ if } e = 0$

Данный подход позволяет добиться нескольких профитов: 

* Ноль выражается (он входит в ненормальный диапазон)
* Для различных $x$ и $y$ выполняется 
$x \neq y \Leftrightarrow \circ(x-y) \neq 0$
* Появляется возможность хранить бесконечные значения ($\pm\infty$)
* Возможность сохранять значение NaN (not-a-number), в котором ко всему прочему 
хранить дополнительную информацию
    * Сравнения NaN-значений дешевы как и сравнения integer

### Сравнение чисел с плавающей точкой

Результатом сравнения двух чисел с плавающей точкой могут стать четыре исхода

1) Неупорядочены (в случае если хотя бы один из операндов - NaN)
2) Равно
3) Меньше
4) Больше

В C и C++ нет проверки на неупорядоченность, поэтому можно пользоваться 
следующими хитростями:

* $x != x -$ верно в случае, если x является NaN
* $x < y \text{ это не то же самое, что } !(x >= y)$

### Округление чисел с плавающей точкой

Базовые операции для чисел с плавающей точкой определяются следующим образом: 
выполнение происходит с бесконечной точкой, а затем происходит округление 
результата. Иными словами, это можно записать в виде:

$$
    x \oplus y = \circ (x + y)
$$

Над числами с плавающей точкой определяются следующие арифметические операции:
$+$, $-$, $\cdot$, $/$, $\sqrt{x}$, остаток, комбинация умножения и сложения
(так же известная как `fma` в C/C++). Ниже перечислены различные правила 
округления для чисел с плавающей точкой:

* К ближайшему (к ближайшему четному)
* К нулю
* К $+\infty$ ($-\infty$)

### Лемма Стербенза

Для двух чисел $x$ и $y$, отличающихся не более чем на степень двойки

$$
    \frac{x}{2} \leqslant y \leqslant 2x
$$

их разность представима в виде

$$
    \circ (x - y) = x - y
$$

Иными словами: для таких чисел отсутствует ошибка округления при вычитании.

> Было бы неплохо сказать про суммирование с сокращенными потерями (суммирование 
Кахана), но это дичь какая-то, фокусы с остатками...

## Билет 4: Организация кеш-памяти. Автоматический и явный префетчинг. Cache-aware и cache-oblivious алгоритмы. Инструмент pahole.

Рассмотрим возможность кэширования для одного процессора.

**Основная мотивация**: использование локальности:
 - Временная локальность
 - Пространственная локальность

**Идея**: Хранить копии оперативной памяти вблизи к процессуру. 
  - Чанки фиксированной длины (в основном 64 байта)
  - Присутствуют тэги статуса и адресса
  
**Характеристики кэша**:
  - Вместимость
  - Размер линии кэша
  - Ассоциативность
  - Наследованные характеристики:
    - Set size: размер линии кэша **х** ассоциативность
    - Set count: вместимость / set size

Кэш память в процессорах разделяется на три уровня. С возрастанием уровня объем 
кэша возрастает, а время доступа к нему увеличивается. Время доступа к любому 
из кэшей значительно меньше времени доступа к оперативной памяти (за счет 
расположения вблизи процессора). При этом ограничением является объем кэшей, 
так как именно из-за малого размера они позволяют добиться высокой скорости.

Кэш-память первого уровня (L1-cache) на кристалле зачастую разделяется на два
физических модуля: L1-instruction и L1-data. Это объясняется тем, что первый 
из кэшей должен находиться ближе к началу конвейера, а второй - ближе к концу 
конвейера.

Данные из оперативной памяти копируются в кэши чанками (обычно 64 байта). 
Скопированным данным выставляется тэг, отражающий их реальное расположение в 
памяти. Это позволяет искать необходимые данные в кэшах, вместо того, чтобы
искать их по их реальному расположению.

В случае, если необходимые данные не были обнаружены в кэше, то процессор 
пытается найти их в кэшах более высокого порядка, а если данные не нашлись и 
там, то производится поиск в оперативной памяти. Таким образом получается, что
в случае успешного обнаружения данных в кэшах мы экономим значительное кол-во
времени на поиск данных в оперативной памяти. 

В кэш данные попадают при первом обращении (причем изначально данные помещаются 
в кэши высших порядков, а при последующих обращениях переехжают в более близкие 
к процессору кэши). В дальнейшем данные могут быть замещены другими. Однако в 
таком случае мы рискуем часто промахиваться мимо кэша, так как в некоторых 
ситуациях данные будут вытеснены из кэша до следующего обращения к ним. 

Для решения данной проблемы существует "префетчинг". В этом случае процессор 
старается размещать данные в кэшах не по принципу последнего обращения, а 
исходя из оптимальности размещения тех или иных данных в кэше. Однако такой 
подход не всегда оказывается оптимальным, так как:

* Префетчинг детектирует только простейшие циклы
* На некоторых архитектурах префетчинг может значительно замедлить исполнение
* Префетчинг чувствителен к дистанции. В некоторых случаях он может слишком 
поздно заполнить кэши, в других заполнить их слишком рано, что приведет к 
выселению данных из кэша до их востребования.

Таким образом, мы приходим к тому, что можно использовать два подхода к 
высокоуровнемым оптимизациям кэшей:

1) __Явный__ (_cache-aware_)
    1) Обработка данных выполняется чанками, согласованными с размерами кэшей
    2) Для оптимизации попадания в кэши разных уровней, используется 
    иерархическое разделение на чанки, согласованные с размерами всех кэшей
2) __Неявный__ (_cache-oblivious_)
    1) Использование асимптотически оптимальных паттернов доступа для любых 
    размеров кэшей
    2) Алгоритмы, действующие по принципу "разделяй и властвуй", например 
    `QuickSort`, `FFT` и прочие им подобные

Для ассистирования в написании кэш-оптимального кода и оптимизации кэшей 
существует несколько механизмов:

* Ключ `-fprefetch-loop-arrays` в `GCC` позволяет провести префетчинг
* Инструмент `pahole` позволяет обнаруживать неоптимальные разметки (порядок
следования полей) структур в `C`

## Билет 5: Поддержка согласованности кешей на многоядерных процессорах. Эффект false sharing.

В случае многопоточного исполнения кэши могут породить некоторые проблемы 
(несогласованность кэшей). Проиллюстрировать данную проблему можно следующим 
примером:

```c
int x = 0;
int y = 0; // same cache line as x

Thread 1:           Thread 2:
x = 1;              y = 1;

Cache contents:
{ }                 { }
{ x: 0, y: 0 }      { }
{ x: 0, y: 0 }      { x: 0, y: 0 }
{ x: 1, y: 0 }      { x: 0, y: 0 }
{ x: 1, y: 0 }      { x: 0, y: 1 }
```

В данном примере в оперативную память поочередно запишутся каждая из линий, 
причем запись будет происходить в одно и то же место (т.к. shared memory). 
Из-за этого можно наблюдать потерю одного из изменений.

### MESI Protocol

Для решения данной проблемы используется протокол MESI. Этот механизм вводит 
для каждой линии состояние. Эти состояния перечислены ниже:

* __Invalid__: линия кэша непригодна для использования
* __Shared__: доступно для чтения, неиспорчена, может иметь копии в других кэшах
* __Exclusive__: доступно для записи, неиспорчена, не имеет копий в других кэшах
* __Modified__: доступно для записи, изменена, не имеет копий в других кэшах

Переход в режим Exclusive выполняется посредством запроса на владение 
Request-for-Ownership (RFO). В данном случае модификация не производится, пока 
не будет получено подтверждение от остальных кэшей.

На практике используются модификации данного протокола с дополнительными 
состояниями.

Может наблюдаться следующая ситуация:

```c
int x = 0, y = 0, r0, r1;

T0              T1
x = 1;          y = 1;
r0 = y;         r1 = x;

// In rare cases r0 == r1 == 0 may be observed
```

## Билет 6: Низкоуровневые средства взаимодействия параллельных потоков: атомарные операции, futex. Поддержка атомарных операций в языке Си.

### Атомарные операции

Проблемы гонки (конкурентного исполнения) можно решить с помощью барьеров, 
блокировок и атомарных операций. **Атомарная операция** - это операция, которая 
выполняется непрерывно, без прерываний со стороны других потоков. Атомарные 
операции позволяют безопасно осуществлять доступ к общей памяти. и допускают 
редактирование только из одного потока. Ниже перечислены основные атомарные 
операции:

* Обмен данных
* Базовые арифметические и логические операции (atomic add, atomic bitwise 
or/and)
* Сравнение с последующей заменой (CAS)

Стоит отметить, что основные базовые операции можно реализовать с помощью CAS.
В языке C поддержка атомарных операций зависит от стандарта C и компилятора.

1. **C11 и атомарные типы:**
   - Стандарт C11 ввел новый заголовочный файл `stdatomic.h`, который 
   предоставляет атомарные типы данных и операции. Например, `atomic_int` - это 
   атомарный целочисленный тип.

2. **GCC и встроенные функции:**
   - Некоторые компиляторы, такие как GCC, предоставляют встроенные функции для 
   атомарных операций.

### futex

**Futex** (fast userspace mutex) - это механизм синхронизации в ядре Linux, 
который позволяет реализовывать примитивы синхронизации в пользовательском 
пространстве более эффективно. Он обеспечивает возможность блокировки потоков 
в пользовательском пространстве и, только при необходимости, взаимодействует 
с ядром для выполнения более сложных операций.

Futex может использоваться напрямую в коде на C с использованием системных 
вызовов или через высокоуровневые библиотеки синхронизации, такие как pthreads.

Механизм futex позволяет реализовать схему wait-notify. Он позволяет оставить 
потоки ожидать уведомления, которое даст им понять, что можно продолжать работу. 

## Билет 7: OpenMP. Основные принципы (fork-join параллелизм на общей памяти, аннотации кода в виде прагм). Компиляторная трансляция OpenMP-конструкций.

**OpenMP (Open Multi-Processing)** представляет собой набор директив 
компилятора и библиотеки для создания параллельных программ на общей памяти. 
Основными принципами OpenMP являются fork-join параллелизм и использование 
аннотаций в виде прагм (pragma) для указания компилятору областей кода, которые 
могут быть выполнены параллельно.

### Принципы OpenMP:

1. **Fork-Join Параллелизм:**
   - **Fork:** Исходный поток исполнения называется "мастер-поток". Когда 
   мастер-поток встречает директиву OpenMP, программа форкается, и создаются 
   дополнительные потоки (рабочие потоки), которые выполняют код, указанный 
   внутри параллельного блока.
   - **Join:** После выполнения кода внутри параллельного блока, все потоки 
   снова объединяются, и управление передается мастер-потоку.

2. **Директивы (Pragma):**
   - Аннотации кода в виде прагм предоставляются для обозначения участков кода, 
   которые должны выполняться параллельно.
   - Пример директивы:
     ```c
     #pragma omp parallel for
     for (int i = 0; i < N; ++i) {
         // Parallelized loop body
     }
     ```

3. **Работа с Общей Памятью:**
   - OpenMP предназначен для параллелизма на общей памяти, где несколько 
   потоков имеют доступ к общим данным.
   - OpenMP предоставляет механизмы для обеспечения корректности выполнения 
   параллельных программ, такие как private, shared и reduction переменные.

### Компиляторная Трансляция OpenMP-Конструкций:

1. **Распознавание Директив:**
   - Компиляторы, поддерживающие OpenMP, распознают директивы OpenMP в исходном 
   коде, начинающиеся с `#pragma omp`.

2. **Анализ Зависимостей и Оптимизации:**
   - Компилятор производит анализ зависимостей данных, чтобы определить, какие 
   участки кода могут быть выполнены параллельно.
   - Выполняются различные оптимизации, такие как векторизация циклов, 
   развертывание циклов, и т.д.

3. **Генерация Кода:**
   - Компилятор генерирует код для каждого потока, включая необходимые 
   механизмы синхронизации и обработки общих данных.
   - Дополнительный код может быть вставлен для создания и управления рабочими 
   потоками.

4. **Создание Экземпляров Потоков:**
   - Во время выполнения программа форкается, и каждый поток выполняет свою 
   собственную копию кода внутри параллельного блока.

5. **Объединение Потоков:**
   - После завершения выполнения параллельного блока, все потоки объединяются, 
   и управление передается обратно мастер-потоку.

## Билет 8: Профилирование программ: через инструментирование кода, на модельном процессоре (Cachegrind, Callgrind). Профилирование с помощью аппаратных счетчиков.

1. __Инструментирование кода__:
- Этот метод включает в себя вставку дополнительного кода (инструментации) в 
исходный код программы с целью сбора информации о производительности во 
время выполнения.

2. __Модельные процессоры (Cachegrind, Callgrind)__:

- Cachegrind
  - Cachegrind является инструментом, включенным в фреймворк Valgrind, 
  который предоставляет детальную информацию о кэше и кэш-промахах.
  - Результаты Cachegrind включают информацию о кэше, обращениях к памяти, 
  промахах кэша и т.д.

- Callgrind:
  - Callgrind также является инструментом в составе Valgrind и предоставляет 
  информацию о вызовах функций, включая количество вызовов, потраченное время 
  и др.
  - Результаты Callgrind включают статистику вызовов функций, расходы по 
  времени и связи между функциями.

3. __Профилирование с использованием аппаратных счетчиков__:

- Некоторые процессоры оборудованы аппаратными счетчиками, которые могут 
быть использованы для измерения различных параметров производительности, 
таких как количество инструкций, промахи кэша, и так далее.
- Примеры аппаратных счетчиков включают в себя Performance Monitoring 
Counters (PMC) на процессорах Intel и аналогичные возможности на других 
процессорах.
- Командный инструмент perf позволяет собирать информацию с аппаратных 
счетчиков и предоставляет обширные возможности профилирования.
