## Билет 1: Параллелизм в пределах одного процессорного ядра и контекста выполнения: архитектурные возможности и компиляторные подходы к повышению параллелизма на уровне команд.

### 1. Конвейер
Для того чтобы ускорить исполнение машинных инструкций был придуман конвейер. В 
общем случае инструкции проходят 5 этапов:

1) __Fetch__ - Чтение байтов инструкции из памяти
2) __Decode__ - Парсинг команды, помещение регистров в _регистровый файл_
3) __Execute__ - Исполнение команды (вычисление результата 
исполнение на одном из доступных ALU (Арифметико-логическое устройство)
4) __Memory access__ - Чтение или запись в оперативную память
5) __Writeback__ - Запись результата в _регистровый файл_

Вместо того, чтобы исполнять все шаги последовательно для каждой инструкции, 
можно организовать конвейер - как только инструкция пройдет первый этап, 
посылать на первый этап следующаю инструкцию. Таким образом удастся добиться 
некоторого параллелизма исполнения.

```
Single-cycle processor
       IF  ID  EX  WB
                       IF  ID  EX  WB
Pipelined processor
       IF  ID  EX  WB
           IF  ID  EX  WB
               IF  ID  EX  WB
                   IF  ID  EX  WB
                       IF  ID  EX  WB
cycle: 0   1   2   3   4   5   6   7
```
Однако в некоторых ситуациях конвейеризация не работает. В качестве примера 
можно рассмотреть ситуацию, когда после вычисления результата какой-либо 
инструкции (например NEG) необходимо записать результат в оперативную память 
(ST). Мы не можем сразу после этапа исполнения для NEG начать исполнять ST, так 
как результат операции NEG еще не записан. Таким образом, возникает т.н. 
"пузырь", то есть весь конвейер ждет, пока результат операции NEG не будет 
записан. Существуют несколько видов зависимостей, из-за которых в конвейере 
возникают "пузыри".

* __Антизависимость__ - запись после чтения
* __Зависимость по выходу__ - запись после записи
* __Истинная__ - чтение после записи
* __Условное ветвление__ (мы не можем предсказать в какую сторону пойдет 
исполнение до вычисления условия
* __Вызов/возврат__ (аналогично предыдущему, мы не можем предугадать куда 
произойдет прыжок)

Для решения проблем с такими зависимостями существует несколько механизмов, о 
которых речь пойдет далее.

### 2. Переименование регистров
Данный подход позволяет решить проблему антизависимостей и зависимостей по 
выходу. С помощью переименования регистров мы можем разнести данные в разные 
регистры, что позволит им быть независимыми. Тогда мы сможем оптимизировать 
конвейер, чтобы в нем не возникало "пузырей". Приведем пример кода на ASM, в 
котором используется переименования регистров для избежания зависимостей.

```nasm
L1: LD r1, [r0]            L1: LD r1, [r0]
    -- bubble --               MOV r3, r0 <- перенесли в другой регистр
    NEG r1                     NEG r1
    -- bubble --               ADD r0, 4
    ST [r0], r1                ST [r3], r1
    ADD r0, 4                  CMP r0, r2
    -- bubble --               JLE L1
    CMP r0, r2
    JLE L1
```

Видно, что удалось избежать зависимостей, что позволило полностью заполнять 
конвейер и завершить итерацию цикла раньше, чем в первом варианте.

Кроме того, можно изменить порядок инструкций, чтобы избежать задержек на 
конвейере. Это называется "insruction scheduling". Стоит отметить, что изменение 
порядка инструкций может помочь также сэкономить энергозатраты, минимизируя 
переключение битов.

К минусам данного подхода можно отнести 

* Конфиликт с аллокацией регистров при компиляции (приходится заново планировать 
аллокацию регистров после оптимизации)
* _Зависимости времени компиляции_
* Простейшие алгоритмы _ренейминга_ работают только на ацикличных ГПУ

### 3. Суперскалярное исполнение

Суперскалярным исполнением называют подход, при котором в процессоре имеются 
дублирующие юниты, которые позволяют выполнять __две и более__ инструкции за 
один такт (_независимо от конвейера_). Это позволяет не только ускорить 
исполнение программы, но и оптимизировать некоторые инструкции (например, 
использующие ALU и FPU).

### 4. Спекулятивное исполнение
Интересно, полезно, но нихрена не понятно.

### 5. Branch Prediction

Помимо классических методов избежания зависимостей, может использоваться 
предсказание условных ветвлений и вызовов/возвратов. Данный метод основан на 
возможности с высокой вероятностью предугадать поведение определенных ветвлений. 
Например, JMP в конце цикла, повторяющегося несколько раз, с большой 
вероятностью будет вести на начало итерации. Таким образом, в большинстве своем, 
конвейер заполняется из предположения, что прыжок будет осуществлен на начало 
цикла. Так как выход из цикла будет осуществляться лишь единожды, ошибка 
заполнения конвейера в этом случае будет незначительно на фоне успешно 
предсказанных прыжков на начало итерации. 

Предсказание условных переходов производится несколькими путями:

* __Во время исполнения__. В данном случае предсказание на текущий переход 
строится исходя из поведения данного перехода в предыдущие разы. Так для цикла 
после нескольких итераций процессор будет успешно предсказывать, что исполнение 
будет прыгать на начало итерации, а ошибка предсказания на последней итерации 
будет незначительна на фоне предшествующих успешных предсказаний.
* __При компиляции__. В этом случае мы можем после компиляции программы 
запустить ее вместе с анализатором, который соберет статистику по условным п
ереходам. Далее программу можно будет перекомпилировать с учетом этой 
статистики, чтобы улучшить качество предсказания условных переходов.

Помимо предсказания условных переходов можно предсказывать и адрес вызова и 
возврата из функции, чтобы сразу запускать в конвейер инструкции, которые 
необходимо будет исполнить после исполнения вызова или возврата.

### 6. VLIW
Нихрена не понятно опять

### 7. Предикаты
Предикаты позволяют развернуть код с ветвлением в линейный код, использующих 
предикативный бит. Это позволяет _одновременно обрабатывать_ несколько веток 
исполнения ценой большего количества инструкций, которые нужно профетчить.

> надо проверить по презентации, ощущение что я что-то забыл упомянуть.

## Билет 2: SIMD-расширения: поддержка в ОС и компиляторах, доступные возможности использования (ассемблер, расширения языка, автовекторизация).

### SIMD-инструкции

SIMD-инструкции позволяют производить операции над множеством данных с помощью
одной инструкции (**S**ingle **I**nstruction **M**ultiple **D**ata). Для 
реализации данного функционала в процессорах были созданы специальные 
расширенные регистры (MMX, SSE, AVX в процессорах x86 и VFP, NEON, Helium, SVE
в Arm-процессорах).

Появление SIMD привело к некоторым трудностям со стороны поддержки операционной
системы:

* Переключения контекста
* Сигнальные фреймы
* Нелокальный ГПУ

Таким образом для успешной работы данного подхода необходимо, чтобы процессор,
ядро ОС и библиотеки работали в кооперации.

Из-за этого компилятор не может автоматически векторизовывать данные, поэтому
часто производители процессоров выпускают библиотеки, содержащие т.н. 
интрисики - методы, позволяющие напрямую указывать компилятору на использование 
SIMD-инструкций. Благодаря этому программист может описать несколько вариантов 
обработки данных - для процессоров, поддерживающих SIMD и для процессоров, их не
поддерживающих. Для этого используется условная компиляция.

> Звучит как будто я больше ничего написать не могу по этому поводу

## Билет 3: Вычисления с плавающей точкой. Принципы IEEE-754. Ограничения и возможности компиляторной трансляции.

### Хранение чисел с плавающей точкой

Вычисления с плавающей точкой описываются в стандарте IEEE-754. Он гласит 
следующее:

* Формат хранения чисел с плавающей точкой в памяти
* Операции над числами с плавающей точкой и правила их округления
* Исключения

Числа с плавающей точкой хранятся в памяти в виде знака, мантиссы и экспоненты.

$$
    r = (-1)^s \cdot M \cdot 2^E
$$

Однако в данном случае допускается неоднозначность кодировки. Рассмотрим это на 
примере числа `6.`

$$
    6. = (-1)^0 \cdot 0011_b \cdot 2^1 \\
    6. = (-1)^0 \cdot 0110_b \cdot 2^0
$$

Для решения этой проблемы было введено ограничение на мантиссу: 
$M \equiv 1.m_1m_2m_3...$. Таким образом запись числа `6` будет выглядеть 
следующим образом:

$$
    6. = (-1)^0 \cdot 1.100_b \cdot 2^2
$$

При этом остается еще несколько проблем:

* Невозможность представить $0$
* Область низкой точности около нуля

Для решения данных проблем вводятся два типа мантисс. В первую очередь 
выбирается сдвиг экспоненты $E_{bias}$: 

* __матисса нормального диапазона__: 
$M = 1.m_1m_2m_3..., E=E_{bias} + e \text{ if } e > 0$
* __мантисса ненормального диапазона__:
$M = 0.m_1m_2m_3..., E=E_{bias} + 1 \text{ if } e = 0$

Данный подход позволяет добиться нескольких профитов: 

* Ноль выражается (он входит в ненормальный диапазон)
* Для различных $x$ и $y$ выполняется 
$x \neq y \Leftrightarrow \circ(x-y) \neq 0$
* Появляется возможность хранить бесконечные значения ($\pm\infty$)
* Возможность сохранять значние NaN (not-a-number), в котором ко всему прочему
хранить дополнительную информацию
    * Сравнения NaN-значений дешевы как и сравнения integer

### Сравнение чисел с плавающей точкой

Результатом сравнения двух чисел с плавающей точкой могут стать четыре исхода

1) Неупорядочены (в случае если хотя бы одно из чисел - NaN)
2) Равно
3) Меньше
4) Больше

В C и C++ нет проверки на неупорядоченность, поэтому можно пользоваться 
следующими хитростями:

* $x != x = true$ в случае, если x является NaN
* $x < y \not\equiv \neg (x >= y)$

### Округление чисел с плавающей точкой

Базовые операции для чисел с плавающей точкой определяются следующим образом:
выполнение происходит с бесконечной точкой, а затем происходит округление 
результата. Иными словами, это можно записать в виде:

$$
    x \oplus y = \circ (x + y)
$$

Над числами с плавающей точкой определяются следующие арифметические операции:
$+$, $-$, $\cdot$, $/$, $\sqrt{x}$, остаток, комбинация умножения и сложения
(так же известная как `fma` в C/C++). Ниже перечислены различные правила 
округления для чисел с плавающей точкой:

* К ближайшему (к ближайшему четному)
* К нулю
* К $+\infty$ ($-\infty$)

### Лемма Стербенза

Для двух чисел $x$ и $y$, отличающихся не более чем на степень двойки

$$
    \frac{x}{2} \leqslant y \leqslant 2x
$$

их разность представима в виде

$$
    \circ (x - y) = x - y
$$

Иными словами: для таких чисел отсуствтвует ошибка округления при вычитании.

> Было бы неплохо сказать про суммирование с сокращенными потерями (суммирование 
Кахана), но это дичь какая-то, фокусы с остатками...

## Билет 4: Организация кеш-памяти. Автоматический и явный префетчинг. Cache-aware и cache-oblivious алгоритмы. Инструмент pahole.



## Билет 5: Поддержка согласованности кешей на многоядерных процессорах. Эффект false sharing.



## Билет 6: Низкоуровневые средства взаимодействия параллельных потоков: атомарные операции, futex. Поддержка атомарных операций в языке Си.



## Билет 7: OpenMP. Основные принципы (fork-join параллелизм на общей памяти, аннотации кода в виде прагм). Компиляторная трансляция OpenMP-конструкций.



## Билет 8: Профилирование программ: через инструментирование кода, на модельном процессоре (Cachegrind, Callgrind). Профилирование с помощью аппаратных счетчиков.

