## Билет 1: Параллелизм в пределах одного процессорного ядра и контекста выполнения: архитектурные возможности и компиляторные подходы к повышению параллелизма на уровне команд.

### 1. Конвейер
Для того чтобы ускорить исполнение машинных инструкций был придуман конвейер. В 
общем случае инструкции проходят 5 этапов:

1) __Fetch__ - Чтение байтов инструкции из памяти
2) __Decode__ - Парсинг команды, помещение регистров в _регистровый файл_
3) __Execute__ - Исполнение команды (вычисление результата 
исполнение на одном из доступных ALU (Арифметико-логическое устройство)
4) __Memory access__ - Чтение или запись в оперативную память
5) __Writeback__ - Запись результата в _регистровый файл_

Вместо того, чтобы исполнять все шаги последовательно для каждой инструкции, 
можно организовать конвейер - как только инструкция пройдет первый этап, 
посылать на первый этап следующаю инструкцию. Таким образом удастся добиться 
некоторого параллелизма исполнения.

```
Single-cycle processor
       IF  ID  EX  WB
                       IF  ID  EX  WB
Pipelined processor
       IF  ID  EX  WB
           IF  ID  EX  WB
               IF  ID  EX  WB
                   IF  ID  EX  WB
                       IF  ID  EX  WB
cycle: 0   1   2   3   4   5   6   7
```
Однако в некоторых ситуациях конвейеризация не работает. В качестве примера 
можно рассмотреть ситуацию, когда после вычисления результата какой-либо 
инструкции (например NEG) необходимо записать результат в оперативную память 
(ST). Мы не можем сразу после этапа исполнения для NEG начать исполнять ST, так 
как результат операции NEG еще не записан. Таким образом, возникает т.н. 
"пузырь", то есть весь конвейер ждет, пока результат операции NEG не будет 
записан. Существуют несколько видов зависимостей, из-за которых в конвейере 
возникают "пузыри".

* __Антизависимость__ - запись после чтения
* __Зависимость по выходу__ - запись после записи
* __Истинная__ - чтение после записи
* __Условное ветвление__ (мы не можем предсказать в какую сторону пойдет 
исполнение до вычисления условия
* __Вызов/возврат__ (аналогично предыдущему, мы не можем предугадать куда 
произойдет прыжок)

Для решения проблем с такими зависимостями существует несколько механизмов, о 
которых речь пойдет далее.

### 2. Переименование регистров
Данный подход позволяет решить проблему антизависимостей и зависимостей по 
выходу. С помощью переименования регистров мы можем разнести данные в разные 
регистры, что позволит им быть независимыми. Тогда мы сможем оптимизировать 
конвейер, чтобы в нем не возникало "пузырей". Приведем пример кода на ASM, в 
котором используется переименования регистров для избежания зависимостей.

```nasm
L1: LD r1, [r0]            L1: LD r1, [r0]
    -- bubble --               MOV r3, r0 <- перенесли в другой регистр
    NEG r1                     NEG r1
    -- bubble --               ADD r0, 4
    ST [r0], r1                ST [r3], r1
    ADD r0, 4                  CMP r0, r2
    -- bubble --               JLE L1
    CMP r0, r2
    JLE L1
```

Видно, что удалось избежать зависимостей, что позволило полностью заполнять 
конвейер и завершить итерацию цикла раньше, чем в первом варианте.

Кроме того, можно изменить порядок инструкций, чтобы избежать задержек на 
конвейере. Это называется "insruction scheduling". Стоит отметить, что изменение 
порядка инструкций может помочь также сэкономить энергозатраты, минимизируя 
переключение битов.

К минусам данного подхода можно отнести 

* Конфиликт с аллокацией регистров при компиляции (приходится заново планировать 
аллокацию регистров после оптимизации)
* _Зависимости времени компиляции_
* Простейшие алгоритмы _ренейминга_ работают только на ацикличных ГПУ

### 3. Суперскалярное исполнение

Суперскалярным исполнением называют подход, при котором в процессоре имеются 
дублирующие юниты, которые позволяют выполнять __две и более__ инструкции за 
один такт (_независимо от конвейера_). Это позволяет не только ускорить 
исполнение программы, но и оптимизировать некоторые инструкции (например, 
использующие ALU и FPU).

### 4. Спекулятивное исполнение
Интересно, полезно, но нихрена не понятно.

### 5. Branch Prediction

Помимо классических методов избежания зависимостей, может использоваться 
предсказание условных ветвлений и вызовов/возвратов. Данный метод основан на 
возможности с высокой вероятностью предугадать поведение определенных ветвлений. 
Например, JMP в конце цикла, повторяющегося несколько раз, с большой 
вероятностью будет вести на начало итерации. Таким образом, в большинстве своем, 
конвейер заполняется из предположения, что прыжок будет осуществлен на начало 
цикла. Так как выход из цикла будет осуществляться лишь единожды, ошибка 
заполнения конвейера в этом случае будет незначительно на фоне успешно 
предсказанных прыжков на начало итерации. 

Предсказание условных переходов производится несколькими путями:

* __Во время исполнения__. В данном случае предсказание на текущий переход 
строится исходя из поведения данного перехода в предыдущие разы. Так для цикла 
после нескольких итераций процессор будет успешно предсказывать, что исполнение 
будет прыгать на начало итерации, а ошибка предсказания на последней итерации 
будет незначительна на фоне предшествующих успешных предсказаний.
* __При компиляции__. В этом случае мы можем после компиляции программы 
запустить ее вместе с анализатором, который соберет статистику по условным п
ереходам. Далее программу можно будет перекомпилировать с учетом этой 
статистики, чтобы улучшить качество предсказания условных переходов.

Помимо предсказания условных переходов можно предсказывать и адрес вызова и 
возврата из функции, чтобы сразу запускать в конвейер инструкции, которые 
необходимо будет исполнить после исполнения вызова или возврата.

### 6. VLIW
Нихрена не понятно опять

### 7. Предикаты
Предикаты позволяют развернуть код с ветвлением в линейный код, использующих 
предикативный бит. Это позволяет _одновременно обрабатывать_ несколько веток 
исполнения ценой большего количества инструкций, которые нужно профетчить.

> надо проверить по презентации, ощущение что я что-то забыл упомянуть.

## Билет 2: SIMD-расширения: поддержка в ОС и компиляторах, доступные возможности использования (ассемблер, расширения языка, автовекторизация).

### SIMD-инструкции

SIMD-инструкции позволяют производить операции над множеством данных с помощью
одной инструкции (**S**ingle **I**nstruction **M**ultiple **D**ata). Для 
реализации данного функционала в процессорах были созданы специальные 
расширенные регистры (MMX, SSE, AVX в процессорах x86 и VFP, NEON, Helium, SVE
в Arm-процессорах).

Появление SIMD привело к некоторым трудностям со стороны поддержки операционной
системы:

* Переключения контекста
* Сигнальные фреймы
* Нелокальный ГПУ

Таким образом для успешной работы данного подхода необходимо, чтобы процессор,
ядро ОС и библиотеки работали в кооперации.

Из-за этого компилятор не может автоматически векторизовывать данные, поэтому
часто производители процессоров выпускают библиотеки, содержащие т.н. 
интрисики - методы, позволяющие напрямую указывать компилятору на использование 
SIMD-инструкций. Благодаря этому программист может описать несколько вариантов 
обработки данных - для процессоров, поддерживающих SIMD и для процессоров, их не
поддерживающих. Для этого используется условная компиляция.

> Звучит как будто я больше ничего написать не могу по этому поводу

## Билет 3: Вычисления с плавающей точкой. Принципы IEEE-754. Ограничения и возможности компиляторной трансляции.

### Хранение чисел с плавающей точкой

Вычисления с плавающей точкой описываются в стандарте IEEE-754. Он гласит 
следующее:

* Формат хранения чисел с плавающей точкой в памяти
* Операции над числами с плавающей точкой и правила их округления
* Исключения

Числа с плавающей точкой хранятся в памяти в виде знака, мантиссы и экспоненты.

$$
    r = (-1)^s \cdot M \cdot 2^E
$$

Однако в данном случае допускается неоднозначность кодировки. Рассмотрим это на 
примере числа `6.`

$$
    6. = (-1)^0 \cdot 0011_b \cdot 2^1 \\
    6. = (-1)^0 \cdot 0110_b \cdot 2^0
$$

Для решения этой проблемы было введено ограничение на мантиссу: 
$M \equiv 1.m_1m_2m_3...$. Таким образом запись числа `6` будет выглядеть 
следующим образом:

$$
    6. = (-1)^0 \cdot 1.100_b \cdot 2^2
$$

При этом остается еще несколько проблем:

* Невозможность представить $0$
* Область низкой точности около нуля

Для решения данных проблем вводятся два типа мантисс. В первую очередь 
выбирается сдвиг экспоненты $E_{bias}$: 

* __матисса нормального диапазона__: 
$M = 1.m_1m_2m_3..., E=E_{bias} + e \text{ if } e > 0$
* __мантисса ненормального диапазона__:
$M = 0.m_1m_2m_3..., E=E_{bias} + 1 \text{ if } e = 0$

Данный подход позволяет добиться нескольких профитов: 

* Ноль выражается (он входит в ненормальный диапазон)
* Для различных $x$ и $y$ выполняется 
$x \neq y \Leftrightarrow \circ(x-y) \neq 0$
* Появляется возможность хранить бесконечные значения ($\pm\infty$)
* Возможность сохранять значние NaN (not-a-number), в котором ко всему прочему
хранить дополнительную информацию
    * Сравнения NaN-значений дешевы как и сравнения integer

### Сравнение чисел с плавающей точкой

Результатом сравнения двух чисел с плавающей точкой могут стать четыре исхода

1) Неупорядочены (в случае если хотя бы одно из чисел - NaN)
2) Равно
3) Меньше
4) Больше

В C и C++ нет проверки на неупорядоченность, поэтому можно пользоваться 
следующими хитростями:

* $x != x = true$ в случае, если x является NaN
* $x < y \not\equiv \neg (x >= y)$

### Округление чисел с плавающей точкой

Базовые операции для чисел с плавающей точкой определяются следующим образом:
выполнение происходит с бесконечной точкой, а затем происходит округление 
результата. Иными словами, это можно записать в виде:

$$
    x \oplus y = \circ (x + y)
$$

Над числами с плавающей точкой определяются следующие арифметические операции:
$+$, $-$, $\cdot$, $/$, $\sqrt{x}$, остаток, комбинация умножения и сложения
(так же известная как `fma` в C/C++). Ниже перечислены различные правила 
округления для чисел с плавающей точкой:

* К ближайшему (к ближайшему четному)
* К нулю
* К $+\infty$ ($-\infty$)

### Лемма Стербенза

Для двух чисел $x$ и $y$, отличающихся не более чем на степень двойки

$$
    \frac{x}{2} \leqslant y \leqslant 2x
$$

их разность представима в виде

$$
    \circ (x - y) = x - y
$$

Иными словами: для таких чисел отсутствует ошибка округления при вычитании.

> Было бы неплохо сказать про суммирование с сокращенными потерями (суммирование 
Кахана), но это дичь какая-то, фокусы с остатками...

## Билет 4: Организация кеш-памяти. Автоматический и явный префетчинг. Cache-aware и cache-oblivious алгоритмы. Инструмент pahole.

Кэш память в процессорах разделяется на три уровня. С возрастанием уровня объем
кэша возрастает, а время доступа к нему увеличивается. Время доступа к любому из
кэшей значительно меньше времени доступа к оперативной памяти (засчет 
расположения вблизи процессора). При этом ограничением является объем кэшей, так
как именно из-за малого размера они позволяют добиться высокой скорости.

Кэш-память первого уровня (L1-cache) на кристалле зачастую разделяется на два
физических модуля: L1-instruction и L1-data. Это объясняется тем, что первый 
из кэшей должен находиться ближе к началу конвейера, а второй - ближе к концу 
конвейера.

Данные из оперативной памяти копируются в кэши чанками (обычно 64 байта). 
Скопированным данным выставляется тэг, отражающий их реальное расположение в 
памяти. Это позволяет искать необходимые данные в кэшах, вместо того, чтобы
искать их по их реальному расположению.

В случае, если необходимые данные не были обнаружены в кэше, то процессор 
пытается найти их в кэшах более высокого порядка, а если данные не нашлись и 
там, то производится поиск в оперативной памяти. Таким образом получается, что
в случае успешного обнаружения данных в кэшах мы экономим значительное кол-во
времени на поиск данных в оперативной памяти. 

> Этот кусок надо проверить, не помню так ли это в действительности

В кэш данные попадают при первом обращении (причем изначально данные помещаются
в кэши высших порядков, а при последующих обращениях переехжают в более близкие
к процессору кэши). В дальнейшем данные могут быть замещены другими. Однако в 
таком случае мы рискуем часто промахиваться мимо кэша, так как в некоторых 
ситуациях данные будут вытеснены из кэша до следующего обращения к ним. 

Для решения данной проблемы существует "префетчинг". В этом случае процессор 
старается размещать данные в кэшах не по принципу последнего обращения, а 
исходя из оптимальности размещения тех или иных данных в кэше. Однако такой 
подход не всегда оказывается оптимальным, так как

* Префетчинг детектирует только простейшие циклы
* На некоторых архитектурах префетчинг может значительно замедлить исполнение
* Префетчинг чувствителен к дистанции. В некоторых случаях он может слишком 
поздно заполнить кэши, в других заполнить их слишком рано, что приведет к 
выселению данных из кэша до их востребования.

Таким образом, мы приходим к тому, что можно использовать два подхода к 
высокоуровнемым оптимизациям кэшей:

1) __Явный__ (_cahce-aware_)
    1) Обработка данных выполняется чанками, согласованными с размерами кэшей
    2) Для оптимизации попадания в кэши разных уровней, используется 
    иерархическое разделение на чанки, согласованные с размерами всех кэшей
2) __Неявный__ (_cache-oblivious_)
    1) Использование асимптотически оптимальных паттернов доступа для любых 
    размеров кэшей
    2) Алгоритмы, действующие по принципу "разделяй и властвуй", например 
    `QuickSort`, `FFT` и прочие им подобные

Для ассистирования в написании кэш-оптимального кода и оптимизации кэшей 
существует несколько механизмов:

* Ключ `-fprefetch-loop-arrays` в `gcc` позволяет провести префетчинг
* Инструмент `pahole` позволяет обнаруживать неоптимальные разметки (порядок
следования полей) структур в C

## Билет 5: Поддержка согласованности кешей на многоядерных процессорах. Эффект false sharing.

В случае многопоточного исполнения кэши могут породить некоторые проблемы 
(несогласованность кэшей). Проиллюстрировать данную проблему можно следующим
примером:

```c
int x = 0;
int y = 0; // same cache line as x

Thread 1:       Thread 2:
x = 1;          y = 1;

Cache contents:
{ }             { }
{ x: 0, y: 0 }  { }
{ x: 0, y: 0 }  { x: 0, y: 0 }
{ x: 1, y: 0 }  { x: 0, y: 0 }
{ x: 1, y: 0 }  { x: 0, y: 1 }
```

В данном примере в оперативную память поочередно запишутся каждая из линий, 
причем запись будет происходить в одно и то же место (т.к. shared memory).
Из-за этого можно наблюдать потерю одного из изменений.

### MESI Protocol

Для решения данной проблемы используется протокол MESI. Этот механизм вводит для
каждой линии состояние. Эти состояния перечислены ниже:

* __Invalid__: линия кэша непригодна для использования
* __Shared__: доступно для чтения, неиспорчена, может иметь копии в других кэшах
* __Exclusive__: доступно для записи, неиспорчена, не имеет копий в других кэшах
* __Modified__: доступно для записи, изменена, не имеет копий в других кэшах

Переход в режим Exclusive выполняется посредством запроса на владение (RFO, 
Request-for-Ownership). В данном случае модификация не производится, пока не 
будет получено подтверждение от остальных кэшей.

На практике используются модификации данного протокола с дополнительными 
состояниями.

Может наблюдаться следующая ситуация (как я понял, даже при наличии MESI):

```c
int x = 0, y = 0, r0, r1;

T0              T1
x = 1;          y = 1;
r0 = y;         r1 = x;

// In rare cases r0 == r1 == 0 may be observed
```

## Билет 6: Низкоуровневые средства взаимодействия параллельных потоков: атомарные операции, futex. Поддержка атомарных операций в языке Си.

### Атомарные операции

Проблемы гонки (конкурентного исполнения) можно решить с помощью барьеров, 
блокировок и атомарных операций. Атомарные операции позволяют безопасно 
осуществлять доступ к общей памяти. Они допускают редактирование только из 
одного потока. Ниже перечислены основные атомарные операции:

* Обмен данных
* Базовые арифметические и логические операции (atomic add, atomic bitwise 
or/and)
* Сравнение с последующей заменой (CAS)

Стоит отметить, что основные базовые операции можно реализовать с помощью CAS.

### futex

Механизм futex позволяет реализовать схему wait-notify. Он позволяет оставить 
потоки ожидать уведомления, которое даст им понять, что можно продолжать работу. 

## Билет 7: OpenMP. Основные принципы (fork-join параллелизм на общей памяти, аннотации кода в виде прагм). Компиляторная трансляция OpenMP-конструкций.

Лень писать подробно, запишу потезисно.

* Параллелизм на общей памяти
* Возможность реализовать параллелизм по задачам (несвязанные участки кода) или 
по данным (например циклы)
* Под капотом реализована архитектура fork-join
* Если проигнорировать все pragma, то получается корректная последовательная 
программа
* Поддержка C/C++/Fortran (изначально писалось под Fortran)
* Разделение на операции времени компиляции (pragma) и времени выполнения 
(libgomp, пример: omp_get_thread_num(), etc)

## Билет 8: Профилирование программ: через инструментирование кода, на модельном процессоре (Cachegrind, Callgrind). Профилирование с помощью аппаратных счетчиков.

Тоже потезисно

* Инструментирование кода - добавление на этапе компиляции инструкций для 
отслеживания исполнения (`-finstrument-functions` в `gcc`)
    * Требует поддержки со стороны компилятора
    * Завышает цену маленьких часто вызываемых функций
* Инструментирование может быть выполнено на более высоком уровне. Инструмент 
Coccinelle добавляет в исходный код инструкции, позволяющие отслеживать и 
профилировать исполнение
* Профилирование сэмплами - можем считать различные события (такты процессора,
промахи кэшей, ошибки предсказания переходов, etc). Пример - утилита `perf`.
Это происходит с помощью аппаратных счетчиков
* Cachegrind и Callgrind - утилиты модельного процессора Valgrind (будь он 
проклят). Valgrind эмулирует работу процессора, а конкретные модули выполняют
сбор и анализ информации, полученной во время исполнения на эмуляторе
