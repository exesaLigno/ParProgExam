## Билет 1: Параллелизм в пределах одного процессорного ядра и контекста выполнения: архитектурные возможности и компиляторные подходы к повышению параллелизма на уровне команд.

### 1. Конвейер
Для того чтобы ускорить исполнение машинных инструкций был придуман конвейер. В 
общем случае инструкции проходят 5 этапов:

1) __Fetch__ - Чтение байтов инструкции из памяти
2) __Decode__ - Парсинг команды, помещение регистров в _регистровый файл_
3) __Execute__ - Исполнение команды (вычисление результата 
исполнение на одном из доступных ALU (Арифметико-логическое устройство)
4) __Memory access__ - Чтение или запись в оперативную память
5) __Writeback__ - Запись результата в _регистровый файл_

Вместо того, чтобы исполнять все шаги последовательно для каждой инструкции, 
можно организовать конвейер - как только инструкция пройдет первый этап, 
посылать на первый этап следующаю инструкцию. Таким образом удастся добиться 
некоторого параллелизма исполнения.

```
Single-cycle processor
       IF  ID  EX  WB
                       IF  ID  EX  WB
Pipelined processor
       IF  ID  EX  WB
           IF  ID  EX  WB
               IF  ID  EX  WB
                   IF  ID  EX  WB
                       IF  ID  EX  WB
cycle: 0   1   2   3   4   5   6   7
```
Однако в некоторых ситуациях конвейеризация не работает. В качестве примера 
можно рассмотреть ситуацию, когда после вычисления результата какой-либо 
инструкции (например NEG) необходимо записать результат в оперативную память 
(ST). Мы не можем сразу после этапа исполнения для NEG начать исполнять ST, так 
как результат операции NEG еще не записан. Таким образом, возникает т.н. 
"пузырь", то есть весь конвейер ждет, пока результат операции NEG не будет 
записан. Существуют несколько видов зависимостей, из-за которых в конвейере 
возникают "пузыри".

* __Антизависимость__ - запись после чтения
* __Зависимость по выходу__ - запись после записи
* __Истинная__ - чтение после записи
* __Условное ветвление__ (мы не можем предсказать в какую сторону пойдет 
исполнение до вычисления условия
* __Вызов/возврат__ (аналогично предыдущему, мы не можем предугадать куда 
произойдет прыжок)

Для решения проблем с такими зависимостями существует несколько механизмов, о 
которых речь пойдет далее.

### 2. Переименование регистров
Данный подход позволяет решить проблему антизависимостей и зависимостей по 
выходу. С помощью переименования регистров мы можем разнести данные в разные 
регистры, что позволит им быть независимыми. Тогда мы сможем оптимизировать 
конвейер, чтобы в нем не возникало "пузырей". Приведем пример кода на ASM, в 
котором используется переименования регистров для избежания зависимостей.

```nasm
L1: LD r1, [r0]            L1: LD r1, [r0]
    -- bubble --               MOV r3, r0 <- перенесли в другой регистр
    NEG r1                     NEG r1
    -- bubble --               ADD r0, 4
    ST [r0], r1                ST [r3], r1
    ADD r0, 4                  CMP r0, r2
    -- bubble --               JLE L1
    CMP r0, r2
    JLE L1
```

Видно, что удалось избежать зависимостей, что позволило полностью заполнять 
конвейер и завершить итерацию цикла раньше, чем в первом варианте.

Кроме того, можно изменить порядок инструкций, чтобы избежать задержек на 
конвейере. Это называется "insruction scheduling". Стоит отметить, что изменение 
порядка инструкций может помочь также сэкономить энергозатраты, минимизируя 
переключение битов.

К минусам данного подхода можно отнести 

* Конфиликт с аллокацией регистров при компиляции (приходится заново планировать 
аллокацию регистров после оптимизации)
* _Зависимости времени компиляции_
* Простейшие алгоритмы _ренейминга_ работают только на ацикличных ГПУ

### 3. Суперскалярное исполнение

Суперскалярным исполнением называют подход, при котором в процессоре имеются 
дублирующие юниты, которые позволяют выполнять __две и более__ инструкции за 
один такт (_независимо от конвейера_). Это позволяет не только ускорить 
исполнение программы, но и оптимизировать некоторые инструкции (например, 
использующие ALU и FPU).

### 4. Спекулятивное исполнение
Интересно, полезно, но нихрена не понятно.

### 5. Branch Prediction

Помимо классических методов избежания зависимостей, может использоваться 
предсказание условных ветвлений и вызовов/возвратов. Данный метод основан на 
возможности с высокой вероятностью предугадать поведение определенных ветвлений. 
Например, JMP в конце цикла, повторяющегося несколько раз, с большой 
вероятностью будет вести на начало итерации. Таким образом, в большинстве своем, 
конвейер заполняется из предположения, что прыжок будет осуществлен на начало 
цикла. Так как выход из цикла будет осуществляться лишь единожды, ошибка 
заполнения конвейера в этом случае будет незначительно на фоне успешно 
предсказанных прыжков на начало итерации. 

Предсказание условных переходов производится несколькими путями:

* __Во время исполнения__. В данном случае предсказание на текущий переход 
строится исходя из поведения данного перехода в предыдущие разы. Так для цикла 
после нескольких итераций процессор будет успешно предсказывать, что исполнение 
будет прыгать на начало итерации, а ошибка предсказания на последней итерации 
будет незначительна на фоне предшествующих успешных предсказаний.
* __При компиляции__. В этом случае мы можем после компиляции программы 
запустить ее вместе с анализатором, который соберет статистику по условным п
ереходам. Далее программу можно будет перекомпилировать с учетом этой 
статистики, чтобы улучшить качество предсказания условных переходов.

Помимо предсказания условных переходов можно предсказывать и адрес вызова и 
возврата из функции, чтобы сразу запускать в конвейер инструкции, которые 
необходимо будет исполнить после исполнения вызова или возврата.

### 6. VLIW
Нихрена не понятно опять

### 7. Предикаты
Предикаты позволяют развернуть код с ветвлением в линейный код, использующих 
предикативный бит. Это позволяет _одновременно обрабатывать_ несколько веток 
исполнения ценой большего количества инструкций, которые нужно профетчить.

> надо проверить по презентации, ощущение что я что-то забыл упомянуть.

## Билет 2: SIMD-расширения: поддержка в ОС и компиляторах, доступные возможности использования (ассемблер, расширения языка, автовекторизация).



## Билет 3: Вычисления с плавающей точкой. Принципы IEEE-754. Ограничения и возможности компиляторной трансляции.



## Билет 4: Организация кеш-памяти. Автоматический и явный префетчинг. Cache-aware и cache-oblivious алгоритмы. Инструмент pahole.



## Билет 5: Поддержка согласованности кешей на многоядерных процессорах. Эффект false sharing.



## Билет 6: Низкоуровневые средства взаимодействия параллельных потоков: атомарные операции, futex. Поддержка атомарных операций в языке Си.



## Билет 7: OpenMP. Основные принципы (fork-join параллелизм на общей памяти, аннотации кода в виде прагм). Компиляторная трансляция OpenMP-конструкций.



## Билет 8: Профилирование программ: через инструментирование кода, на модельном процессоре (Cachegrind, Callgrind). Профилирование с помощью аппаратных счетчиков.

